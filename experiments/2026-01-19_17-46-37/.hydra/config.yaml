data:
  n_per_class: 350
  train_split: 0.8
model:
  input_dim: 2
  hidden_dim: 128
  num_layers: 8
  output_dim: 1
  activation: relu
train:
  batch_size: 64
  total_steps: 10000
  learning_rate: 0.001
  weight_decay: 0.0
  use_scheduler: true
  warmup_steps: 100
  log_interval: 100
  eval_interval: 500
  save_best: true
experiment:
  name: two_clouds_mlp
  seed: 42
